# Plano de Migra√ß√£o: PandasAI ‚Üí LangChain

## 1. Vis√£o Geral
Migrar da orquestra√ß√£o simples (PandasAI SmartDataframe) para um framework de cadeia de prompts/agentes (LangChain) com suporte a:
- Hist√≥rico conversacional persistente e contextualizado
- Recupera√ß√£o aumentada (RAG) sobre documentos/PDFs
- Execu√ß√£o de m√∫ltiplos passos (parse PDF ‚Üí extrair dados ‚Üí an√°lise ‚Üí gerar relat√≥rio)
- Ferramentas customizadas (queries SQL, API calls, manipula√ß√£o de DataFrames)

## 2. Passos M√≠nimos de Migra√ß√£o

### Fase 1: Setup de Depend√™ncias (Semana 1)
```bash
uv add langchain langchain-community langchain-openai
uv add langchain-anthropic langchain-google-genai
uv add langchain-text-splitters pypdf python-dotenv
```

### Fase 2: Abstra√ß√£o LLM ‚Üí LangChain (Semana 1-2)
**Novo arquivo**: `src/services/langchain_client.py`
- Wrapper unificado sobre LangChain LLMs (Google, OpenAI, Anthropic)
- Interface compat√≠vel com atual `llm_client.py` para transi√ß√£o gradual
- Exemplo:
  ```python
  from langchain_openai import ChatOpenAI
  from langchain_google_genai import ChatGoogleGenerativeAI
  from langchain_anthropic import ChatAnthropic

  def create_langchain_llm(provider: str, api_key: str, model: str):
      if provider == "google":
          return ChatGoogleGenerativeAI(api_key=api_key, model=model)
      elif provider == "openai":
          return ChatOpenAI(api_key=api_key, model=model)
      elif provider == "anthropic":
          return ChatAnthropic(api_key=api_key, model=model)
  ```

### Fase 3: Converter SmartDataframe ‚Üí Pandas Agent (Semana 2)
**Novo arquivo**: `src/services/langchain_pandas_agent.py`
- Use `langchain.agents.create_pandas_dataframe_agent()`
- Substitui a l√≥gica de `SmartDataframe.chat()` com mais flexibilidade
- Exemplo:
  ```python
  from langchain.agents import create_pandas_dataframe_agent
  
  agent = create_pandas_dataframe_agent(
      llm=llm,
      df=df_ia,
      agent_type="openai-tools",
      verbose=True,
  )
  result = agent.invoke({"input": "Qual √© o total gasto em 2025?"})
  ```

### Fase 4: Adicionar Memory/Hist√≥rico (Semana 2-3)
**Novo arquivo**: `src/services/langchain_memory.py`
- Implementar `ConversationBufferMemory` ou `ConversationSummaryMemory`
- Persistir em SQLite/JSON para entre-sess√µes
- Exemplo:
  ```python
  from langchain.memory import ConversationBufferMemory
  from langchain.chains import ConversationChain
  
  memory = ConversationBufferMemory()
  chain = ConversationChain(llm=llm, memory=memory, verbose=True)
  ```

### Fase 5: Integrar em `pages/3_ü§ñ_Assistente_IA.py` (Semana 3)
- Substituir `SmartDataframe` por `create_pandas_dataframe_agent()`
- Adicionar memory para hist√≥rico entre mensagens
- Usar novo `langchain_client.py` para LLM setup
- Testar com mesmos dados/queries existentes

### Fase 6: Adicionar RAG (Opcional, Semana 4+)
**Se decidir incluir busca em PDFs/hist√≥rico de faturas:**
- Use `langchain.document_loaders.PDFPlumberLoader` (compat√≠vel com seu `pdfplumber`)
- Integrate embedding + vector store (FAISS, Chroma, Pinecone)
- Chain: `RetrievalQA` ou `RetrievalAgentExecutor`

## 3. Riscos e Mitiga√ß√£o

| Risco | Impacto | Mitiga√ß√£o |
|-------|---------|-----------|
| Quebra de compatibilidade com prompts PandasAI | Alto | Manter `llm_client.py` em paralelo; testar prompts lado-a-lado |
| Custo de tokens aumenta (hist√≥rico + memory) | M√©dio | Implementar `ConversationSummaryMemory`; limpar hist√≥rico antigo |
| Performance pior com DataFrames grandes | M√©dio | Usar `tools_for_pandas_agent` com pr√©-filtros; cache queries |
| Depend√™ncias adicionais inflam projeto | Baixo | Usar `extras` do LangChain; remover PandasAI quando deprecated |
| Transi√ß√£o quebra fluxo do usu√°rio | Alto | Parallelizar ambos; switch via flag de env `USE_LANGCHAIN=true` |

## 4. Timeline Estimada
- **Semana 1**: Setup deps + abstra√ß√£o LLM + testes unit√°rios
- **Semana 2**: Pandas agent + primeira integra√ß√£o UI (lado-a-lado)
- **Semana 3**: Memory + hist√≥rico persistente + testes E2E
- **Semana 4+**: RAG (se desejado) + cleanup PandasAI

## 5. Exemplo de C√≥digo (N√£o Aplicado ‚Äî Apenas Refer√™ncia)

### `src/services/langchain_client.py`
```python
from langchain_openai import ChatOpenAI
from langchain_google_genai import ChatGoogleGenerativeAI
from langchain_anthropic import ChatAnthropic

def create_langchain_llm(provider: str, api_key: str, model: str):
    """Create a LangChain LLM instance."""
    if provider == "google":
        return ChatGoogleGenerativeAI(api_key=api_key, model=model, temperature=0.7)
    elif provider == "openai":
        return ChatOpenAI(api_key=api_key, model=model, temperature=0.7)
    elif provider == "anthropic":
        return ChatAnthropic(api_key=api_key, model=model, temperature=0.7)
    else:
        raise ValueError(f"Unknown provider: {provider}")
```

### `src/services/langchain_pandas_agent.py`
```python
from langchain.agents import create_pandas_dataframe_agent
from langchain.memory import ConversationBufferMemory

def create_analyst_agent(llm, df, memory=None):
    """Create a PandasAI-like agent using LangChain."""
    agent = create_pandas_dataframe_agent(
        llm=llm,
        df=df,
        agent_type="openai-tools",
        verbose=True,
    )
    return agent

# Usage in Streamlit:
# agent = create_analyst_agent(llm, df_ia)
# result = agent.invoke({"input": user_prompt})
# st.write(result["output"])
```

## 6. Decis√£o: Continuar com PandasAI ou Migrar?

**Recomenda√ß√£o**: Manter PandasAI no curto prazo; preparar migra√ß√£o gradual se:
- ‚úÖ Usu√°rios pedem hist√≥rico conversacional persistente
- ‚úÖ Necessidade de RAG (busca em faturas anteriores/contexto longo)
- ‚úÖ Fluxos multi-step (gerar an√°lise ‚Üí exportar relat√≥rio ‚Üí enviar email)
- ‚ùå Caso contr√°rio, PandasAI √© suficiente e mais simples

---

**Pr√≥ximos Passos Recomendados:**
1. Levantar requisitos espec√≠ficos de orquestra√ß√£o (RAG? History? Tools?)
2. Criar branch `feature/langchain-exploration` com c√≥digo experimental
3. Benchmark: custo de tokens, lat√™ncia, qualidade de respostas (PandasAI vs LangChain)
4. Validar com stakeholders antes de full commit
